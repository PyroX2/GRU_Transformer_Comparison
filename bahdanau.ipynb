{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize string\n",
    "def normalizeString(s):\n",
    "    s = unidecode(s.lower())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIALS = ['<unk>', '<pad>', '<bos>', '<eos>'] # UNK for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data file and read lines\n",
    "with open(\"./data/pol.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# For each line split it by TAB\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.split('\\t')\n",
    "    lines[i] = [normalizeString(line[0]), normalizeString(line[1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be strong.', 'badz silny.']\n"
     ]
    }
   ],
   "source": [
    "# Print example line\n",
    "print(lines[random.randint(0, 1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizers\n",
    "pl_tokenizer = spacy.load(\"pl_core_news_sm\")\n",
    "en_tokenizer = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 2\n",
      "idz\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Test tokenizer\n",
    "tokens = pl_tokenizer(lines[0][1])\n",
    "print('Number of tokens:', len(tokens))\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Counter object works similar to dictionary in which each element is key and value is number of times this element is present\n",
    "pl_counter = Counter()\n",
    "en_counter = Counter()\n",
    "\n",
    "# Lists for storing Polish and English sentences\n",
    "pl_list = []\n",
    "en_list = []\n",
    "\n",
    "# Lists for storing number of tokens in sentences \n",
    "pl_lengths = []\n",
    "en_lengths = []\n",
    "\n",
    "for line in tqdm(lines[:1000]):\n",
    "    # Tokenize sentences\n",
    "    en_tokens = en_tokenizer(line[0])\n",
    "    pl_tokens = pl_tokenizer(line[1])\n",
    "\n",
    "    # Concatenate tokens to lists (each tokenized sentence is different element in the list)\n",
    "    pl_list += pl_tokens\n",
    "    en_list += en_tokens\n",
    "\n",
    "    # Append number of tokens in sentences\n",
    "    pl_lengths.append(len(pl_tokens))\n",
    "    en_lengths.append(len(en_tokens))\n",
    "\n",
    "    # Update counters with new tokens\n",
    "    pl_counter.update(pl_tokens)\n",
    "    en_counter.update(en_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_list = [str(token) for token in pl_list]\n",
    "en_list = [str(token) for token in en_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish tokens:  ['idz', '.', 'czesc', '.', 'uciekaj', '!', 'biegnij', '.', 'uciekaj', '.', 'kto', '?', 'o', ',', 'dziamdzia', 'zaprzala', 'jej', 'szadz', '!', 'lal']\n",
      "English tokens:  ['go', '.', 'hi', '.', 'run', '!', 'run', '.', 'run', '.', 'who', '?', 'wow', '!', 'wow', '!', 'duck', '!', 'fire', '!']\n"
     ]
    }
   ],
   "source": [
    "print('Polish tokens: ', pl_list[:20])\n",
    "print('English tokens: ', en_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torchtext Vocabs from lists of tokens\n",
    "en_vocab = build_vocab_from_iterator([en_list])\n",
    "pl_vocab = build_vocab_from_iterator([pl_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__getitem__(): incompatible function arguments. The following argument types are supported:\n    1. (self: torchtext._torchtext.Vocab, arg0: str) -> int\n\nInvoked with: <torchtext._torchtext.Vocab object at 0x7223c57fb830>, go",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m6547\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (en, pl) \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Tokenizes words, takes each token and gets item from torchtext Vocab. __getitem__ from torchtext Vocab returns index of this token\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     en_tensor_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[43men_vocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m en_tokenizer(en)])\n\u001b[1;32m     12\u001b[0m     fr_tensor_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([pl_vocab[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m pl_tokenizer(pl)]) \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Gets random number from 0 to 1 and adds the token to the appropriate dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.12/site-packages/torchtext/vocab/vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __getitem__(): incompatible function arguments. The following argument types are supported:\n    1. (self: torchtext._torchtext.Vocab, arg0: str) -> int\n\nInvoked with: <torchtext._torchtext.Vocab object at 0x7223c57fb830>, go"
     ]
    }
   ],
   "source": [
    "VALID_PCT = 0.1\n",
    "TEST_PCT  = 0.1\n",
    "\n",
    "train_data = []\n",
    "valid_data = []\n",
    "test_data = []\n",
    "\n",
    "random.seed(6547)\n",
    "for (en, pl) in lines:\n",
    "    # Tokenizes words, takes each token and gets item from torchtext Vocab. __getitem__ from torchtext Vocab returns index of this token\n",
    "    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(en)])\n",
    "    fr_tensor_ = torch.tensor([pl_vocab[token] for token in pl_tokenizer(pl)]) \n",
    "    \n",
    "    # Gets random number from 0 to 1 and adds the token to the appropriate dataset\n",
    "    random_draw = random.random()\n",
    "    if random_draw <= VALID_PCT:\n",
    "        valid_data.append((en_tensor_, fr_tensor_))\n",
    "    elif random_draw <= VALID_PCT + TEST_PCT:\n",
    "        test_data.append((en_tensor_, fr_tensor_))\n",
    "    else:\n",
    "        train_data.append((en_tensor_, fr_tensor_))\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "  Training pairs: {len(train_data):,}\n",
    "Validation pairs: {len(valid_data):,}\n",
    "      Test pairs: {len(test_data):,}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'en_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m PAD_IDX \u001b[38;5;241m=\u001b[39m \u001b[43men_vocab\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m BOS_IDX \u001b[38;5;241m=\u001b[39m en_vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<bos>\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m EOS_IDX \u001b[38;5;241m=\u001b[39m en_vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<eos>\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'en_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "PAD_IDX = en_vocab['<pad>']\n",
    "BOS_IDX = en_vocab['<bos>']\n",
    "EOS_IDX = en_vocab['<eos>']\n",
    "\n",
    "for en_id, fr_id in zip(en_vocab.lookup_indices(SPECIALS), pl_vocab.lookup_indices(SPECIALS)):\n",
    "  assert en_id == fr_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    '''\n",
    "    Prepare English and French examples for batch-friendly modeling by appending\n",
    "    BOS/EOS tokens to each, stacking the tensors, and filling trailing spaces of\n",
    "    shorter sentences with the <pad> token. To be used as the collate_fn in the\n",
    "    English-to-French DataLoader.\n",
    "\n",
    "    Input: \n",
    "    - data_batch, an iterable of (English, French) tuples from the datasets \n",
    "      created above\n",
    "\n",
    "    Outputs\n",
    "    - en_batch: a (max length X batch size) tensor of English token IDs\n",
    "    - fr_batch: a (max length X batch size) tensor of French token IDs \n",
    "    '''\n",
    "    en_batch, fr_batch = [], []\n",
    "    for (en_item, fr_item) in data_batch:\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        fr_batch.append(torch.cat([torch.tensor([BOS_IDX]), fr_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX, batch_first=False)\n",
    "    fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX, batch_first=False)\n",
    "\n",
    "    return en_batch, fr_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go. ###Idź.',\n",
       " 'Hi. ###Cześć.',\n",
       " 'Run! ###Uciekaj!',\n",
       " 'Run. ###Biegnij.',\n",
       " 'Run. ###Uciekaj.',\n",
       " 'Who? ###Kto?',\n",
       " 'Wow! ###O, dziamdzia zaprzała jej szadź!',\n",
       " 'Wow! ###Łał!',\n",
       " 'Duck! ###Unik!',\n",
       " 'Fire! ###Pali się!',\n",
       " 'Fire! ###Strzelaj!',\n",
       " 'Fire! ###Ognia!',\n",
       " 'Help! ###Pomocy!',\n",
       " 'Hide. ###Schowaj się.',\n",
       " 'Jump! ###Skacz!',\n",
       " 'Jump. ###Skok.',\n",
       " 'Stay. ###Zostań.',\n",
       " 'Stop! ###Stój!',\n",
       " 'Stop! ###Zatrzymaj się!',\n",
       " 'Wait! ###Czekaj!',\n",
       " 'Wait! ###Zaczekaj!',\n",
       " 'Wait! ###Poczekaj!',\n",
       " 'Wait! ###Czekajcie!',\n",
       " 'Wait! ###Poczekajcie!',\n",
       " 'Wait! ###Zaczekajcie!',\n",
       " 'Wait! ###Niech pan zaczeka!',\n",
       " 'Wait! ###Niech pani zaczeka!',\n",
       " 'Wait. ###Czekajcie.',\n",
       " 'Wait. ###Zaczekaj.',\n",
       " 'Wait. ###Czekaj.',\n",
       " 'Wait. ###Poczekaj.',\n",
       " 'Wait. ###Poczekajcie.',\n",
       " 'Wait. ###Zaczekajcie.',\n",
       " 'Begin. ###Zaczynaj.',\n",
       " 'Begin. ###Zaczynajcie.',\n",
       " 'Do it. ###Zrób to.',\n",
       " 'Hello! ###Cześć.',\n",
       " 'Hello. ###Cześć.',\n",
       " 'Hurry! ###Pośpiesz się!',\n",
       " 'I hid. ###Ukryłem się.',\n",
       " 'I ran. ###Pobiegłem.',\n",
       " 'I ran. ###Pobiegłam.',\n",
       " 'I see. ###Rozumiem.',\n",
       " 'I see. ###Widzę.',\n",
       " 'I try. ###Próbuje.',\n",
       " 'I won! ###Wygrałem!',\n",
       " 'I won. ###Wygrałem.',\n",
       " 'I won. ###Zwyciężyłem.',\n",
       " 'Oh no! ###O nie!',\n",
       " 'Relax. ###Wyluzuj.',\n",
       " 'Shoot! ###Strzelaj!',\n",
       " 'Shoot! ###Ognia!',\n",
       " 'Smile. ###Uśmiech.',\n",
       " 'Sorry? ###Przepraszam?',\n",
       " 'Ask me. ###Spytaj mnie.',\n",
       " 'Attack! ###Atak!',\n",
       " 'Attack! ###Do ataku!',\n",
       " 'Buy it. ###Kup je.',\n",
       " 'Buy it. ###Kup go.',\n",
       " 'Buy it. ###Kup ją.',\n",
       " 'Cheers! ###Na zdrowie!',\n",
       " 'Cheers! ###Twoje zdrowie!',\n",
       " 'Eat it. ###Zjedz to.',\n",
       " 'Exhale. ###Wydech.',\n",
       " 'Freeze! ###Stój!',\n",
       " 'Freeze! ###Nie ruszaj się!',\n",
       " 'Get up. ###Wstawaj.',\n",
       " 'Go now. ###Idź już.',\n",
       " 'Got it! ###Rozumiem!',\n",
       " 'Got it? ###Rozumiesz?',\n",
       " 'Got it? ###Kapujesz?',\n",
       " 'He ran. ###On pobiegł.',\n",
       " 'Hop in. ###Wskakuj.',\n",
       " 'Hug me. ###Przytul mnie.',\n",
       " 'I care. ###Mi zależy.',\n",
       " 'I fell. ###Przewróciłam się.',\n",
       " 'I fled. ###Uciekłem.',\n",
       " 'I fled. ###Uciekłam.',\n",
       " 'I knit. ###Robiłem na drutach.',\n",
       " 'I knit. ###Robiłam na drutach.',\n",
       " 'I know. ###Wiem.',\n",
       " 'I left. ###Wyjechałam.',\n",
       " 'I left. ###Odszedłem.',\n",
       " 'I left. ###Wyjechałam',\n",
       " 'I left. ###Wyszłam.',\n",
       " 'I left. ###Odeszłam.',\n",
       " 'I left. ###Wyszedłem.',\n",
       " 'I lied. ###Kłamałem.',\n",
       " 'I lied. ###Skłamałem.',\n",
       " 'I lost. ###Przegrałem.',\n",
       " 'I paid. ###Zapłaciłem.',\n",
       " 'I quit. ###Wychodzę.',\n",
       " 'I sang. ###Śpiewałem.',\n",
       " 'I sang. ###Śpiewałam.',\n",
       " 'I spit. ###Splunąłem.',\n",
       " 'I spit. ###Splunęłam.',\n",
       " 'I swim. ###Pływam.',\n",
       " 'I work. ###Pracuję.',\n",
       " \"I'm OK. ###Ze mną wszystko w porządku.\",\n",
       " \"I'm up. ###Wstałem.\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x72b667eb6570>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAGiCAYAAABDFHTaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyvklEQVR4nO3de3RV5Z3/8U8u5MLlnBg05yRDgmmlBRREQOEodbxkiBgdUewMTlSqKIMN1sAUlCmg4iWIVS6KUG8EV6EKswQVKhiDQCkhYDSWiyJqpknFk0ylyQEkCST794e/7OUR2BLyZCeE92utvZZn7+fs58nTQj58n32JsCzLEgAAQCuLbOsBAACAMwOhAwAAuILQAQAAXEHoAAAAriB0AAAAVxA6AACAKwgdAADAFYQOAADgCkIHAABwBaEDAAC4otmhY9OmTbr++uuVkpKiiIgIrVq1Kuy4ZVmaMWOGkpOTFR8fr4yMDO3duzeszf79+5WdnS2Px6OEhASNHTtWBw8ebNEPAgAA2rdmh45Dhw7pwgsv1IIFC457fPbs2Zo/f74WLVqk4uJidenSRZmZmaqtrbXbZGdna9euXSooKNDq1au1adMmjRs37tR/CgAA0O5FtOSFbxEREVq5cqVGjhwp6dsqR0pKiv7rv/5Lv/71ryVJNTU18vl8ys/P1+jRo/Xxxx+rb9++2r59uwYPHixJWrt2ra699lr97W9/U0pKSst/KgAA0O5EmzxZWVmZgsGgMjIy7H1er1dDhgxRUVGRRo8eraKiIiUkJNiBQ5IyMjIUGRmp4uJi3Xjjjcect66uTnV1dfbnxsZG7d+/X927d1dERITJHwEA0MFYlqUDBw4oJSVFkZGtdyljbW2t6uvrW3yemJgYxcXFGRhR+2M0dASDQUmSz+cL2+/z+exjwWBQSUlJ4YOIjlZiYqLd5vvy8vL08MMPmxwqAOAMU1FRoR49erTKuWtraxUfH2/kXH6/X2VlZR0yeBgNHa1l6tSpmjRpkv25pqZGaWlpqqiokMfjacORAQDau1AopNTUVHXr1q3V+jBR4WgSDAZVX19P6Pghfr9fklRZWank5GR7f2VlpQYMGGC3qaqqCvve0aNHtX//fvv73xcbG6vY2Nhj9ns8HkIHAOCkuLUc35J+WnCZ5WnB6OJWenq6/H6/CgsL7X2hUEjFxcUKBAKSpEAgoOrqapWUlNht1q9fr8bGRg0ZMsTkcAAAcFVERESLt46s2ZWOgwcP6rPPPrM/l5WVqbS0VImJiUpLS1Nubq4effRR9erVS+np6Zo+fbpSUlLsO1z69Omja665RnfffbcWLVqkI0eOaMKECRo9ejR3rgAATmsmgkNHrnY0O3S8//77uvLKK+3PTddajBkzRvn5+ZoyZYoOHTqkcePGqbq6WsOGDdPatWvD1qaWLl2qCRMm6Oqrr1ZkZKRGjRql+fPnG/hxAABoO2dCtaIlWvScjrYSCoXk9XpVU1PDNR0AAEdu/M5o6iMqKqrF13Q0NDR02N9vp8XdKwAAnA6odDgjdAAAYAihwxlvmQUAAK6g0gEAgCFUOpwROgAAMITQ4YzlFQAATlMPPfTQMQ8X6927t328trZWOTk56t69u7p27apRo0apsrIy7Bzl5eXKyspS586dlZSUpMmTJ+vo0aNhbTZs2KCBAwcqNjZW5513nvLz809pvIQOAAAMaYsnkp5//vn66quv7G3z5s32sYkTJ+qtt97SihUrtHHjRu3bt0833XSTfbyhoUFZWVmqr6/Xli1btGTJEuXn52vGjBl2m7KyMmVlZenKK69UaWmpcnNzddddd2ndunXNHivLKwAAGNIWyyvR0dHHfXdZTU2NXnrpJS1btkxXXXWVJGnx4sXq06ePtm7dqqFDh+qdd97R7t279e6778rn82nAgAF65JFHdP/99+uhhx5STEyMFi1apPT0dD311FOSvn2y+ObNmzVnzhxlZmY2a6xUOgAAaGdCoVDYVldXd8K2e/fuVUpKin70ox8pOztb5eXlkqSSkhIdOXJEGRkZdtvevXsrLS1NRUVFkqSioiL169dPPp/PbpOZmalQKKRdu3bZbb57jqY2TedoDkIHAACGmFpeSU1Nldfrtbe8vLzj9jdkyBDl5+dr7dq1WrhwocrKyvSzn/1MBw4cUDAYVExMjBISEsK+4/P5FAwGJUnBYDAscDQdbzrm1CYUCunw4cPNmh+WVwAAMMTU8kpFRUXYY9BjY2OP227EiBH2f/fv319DhgxRz549tXz5csXHx7d4HKZR6QAAwBBTlQ6PxxO2nSh0fF9CQoJ+8pOf6LPPPpPf71d9fb2qq6vD2lRWVtrXgPj9/mPuZmn6/ENtPB5Ps4MNoQMAgA7i4MGD+vzzz5WcnKxBgwapU6dOKiwstI/v2bNH5eXlCgQCkqRAIKAdO3aoqqrKblNQUCCPx6O+ffvabb57jqY2TedoDkIHAACGuH3L7K9//Wtt3LhR//u//6stW7boxhtvVFRUlG655RZ5vV6NHTtWkyZN0nvvvaeSkhLdcccdCgQCGjp0qCRp+PDh6tu3r2677TZ99NFHWrdunaZNm6acnBy7ujJ+/Hh98cUXmjJlij755BM999xzWr58uSZOnNjs+eGaDgAADHH7ltm//e1vuuWWW/T111/rnHPO0bBhw7R161adc845kqQ5c+YoMjJSo0aNUl1dnTIzM/Xcc8/Z34+KitLq1at1zz33KBAIqEuXLhozZoxmzpxpt0lPT9eaNWs0ceJEzZs3Tz169NCLL77Y7NtlJSnCsiyr5T+2u0KhkLxer2pqasIutAEA4Pvc+J3R1IfH42lR6LAsS6FQqMP+fqPSAQCAIbx7xRmhAwAAQwgdzriQFAAAuIJKBwAAhlDpcEboAADAoJZeSNqRsbwCAABcQaUDAABDWrq80tGXZggdAAAYQuhwRugAAMAQQoczrukAAACuoNIBAIAhVDqcEToAADCE0OGM5RUAAOAKKh0AABhCpcMZoQMAAEMIHc5YXgEAAK6g0gEAgCFUOpwROgAAMITQ4YzlFQAA4AoqHQAAGEKlwxmhAwAAQwgdzggdAAAYQuhwxjUdAADAFVQ6AAAwhEqHM0IHAACGEDqcsbwCAABcQaUDAABDqHQ4I3QAAGAIocMZyysAAMAVVDoAADCESoczQgcAAAZ19ODQEiyvAAAAV1DpAADAEJZXnBE6AAAwhNDhjNABAIAhhA5nXNMBAABcQaUDAABDqHQ4I3QAAGAIocMZyysAAMAVVDoAADCESoczQgcAAIYQOpyxvAIAAFxBpQMAAEOodDgjdAAAYAihwxnLKwAAwBVUOgAAMIRKhzNCB4ATsiyrQ/ThZj+Rka1fQO7ov5hOZ4QOZ8b/dDQ0NGj69OlKT09XfHy8fvzjH+uRRx4J+wNvWZZmzJih5ORkxcfHKyMjQ3v37jU9FAAAXNUUOlqydWTGQ8cTTzyhhQsX6tlnn9XHH3+sJ554QrNnz9Yzzzxjt5k9e7bmz5+vRYsWqbi4WF26dFFmZqZqa2tNDwcAALQTxpdXtmzZohtuuEFZWVmSpHPPPVd/+MMftG3bNknfVjnmzp2radOm6YYbbpAkvfLKK/L5fFq1apVGjx5tekgAALiC5RVnxisdl156qQoLC/Xpp59Kkj766CNt3rxZI0aMkCSVlZUpGAwqIyPD/o7X69WQIUNUVFR03HPW1dUpFAqFbQAAtDcsrzgzXul44IEHFAqF1Lt3b0VFRamhoUGPPfaYsrOzJUnBYFCS5PP5wr7n8/nsY9+Xl5enhx9+2PRQAQCAi4xXOpYvX66lS5dq2bJl+uCDD7RkyRL99re/1ZIlS075nFOnTlVNTY29VVRUGBwxAABmUOlwZrzSMXnyZD3wwAP2tRn9+vXTX//6V+Xl5WnMmDHy+/2SpMrKSiUnJ9vfq6ys1IABA457ztjYWMXGxpoeKgAARnFNhzPjlY5vvvnmmPvUo6Ki1NjYKElKT0+X3+9XYWGhfTwUCqm4uFiBQMD0cAAAQDthvNJx/fXX67HHHlNaWprOP/98ffjhh3r66ad15513Svo2xeXm5urRRx9Vr169lJ6erunTpyslJUUjR440PRwAAFxDpcOZ8dDxzDPPaPr06frlL3+pqqoqpaSk6D//8z81Y8YMu82UKVN06NAhjRs3TtXV1Ro2bJjWrl2ruLg408MBAMBVHT04tESE5dazgQ0KhULyer2qqamRx+Np6+EAHRaPQW8+HoPe/rjxO6Opj0GDBik6+tT/PX/06FGVlJR02N9vvHsFAABDWF5xRugAAMAQQoez1q8DAgBwhmjr53TMmjXLvmGjSW1trXJyctS9e3d17dpVo0aNUmVlZdj3ysvLlZWVpc6dOyspKUmTJ0/W0aNHw9ps2LBBAwcOVGxsrM477zzl5+c3e3yEDgAAOoDt27frd7/7nfr37x+2f+LEiXrrrbe0YsUKbdy4Ufv27dNNN91kH29oaFBWVpbq6+u1ZcsWLVmyRPn5+WE3gJSVlSkrK0tXXnmlSktLlZubq7vuukvr1q1r1hgJHQAAGNJWlY6DBw8qOztbL7zwgs466yx7f01NjV566SU9/fTTuuqqqzRo0CAtXrxYW7Zs0datWyVJ77zzjnbv3q3f//73GjBggEaMGKFHHnlECxYsUH19vSRp0aJFSk9P11NPPaU+ffpowoQJuvnmmzVnzpxmjZPQAQCAIaZCx/dfclpXV+fYb05OjrKyssJepipJJSUlOnLkSNj+3r17Ky0tzX7JalFRkfr16xf2TrTMzEyFQiHt2rXLbvP9c2dmZp7wRa0nQugAAKCdSU1Nldfrtbe8vLwTtn311Vf1wQcfHLdNMBhUTEyMEhISwvZ/9yWrwWDwuC9hbTrm1CYUCunw4cMn/XNx9woAAIaYunuloqIi7DkdJ3r/WEVFhe677z4VFBScFg/YpNIBAIAhppZXPB5P2Hai0FFSUqKqqioNHDhQ0dHRio6O1saNGzV//nxFR0fL5/Opvr5e1dXVYd+rrKy0X8Dq9/uPuZul6fMPtfF4PIqPjz/p+SF0AABwmrr66qu1Y8cOlZaW2tvgwYOVnZ1t/3enTp3CXrK6Z88elZeX2y9ZDQQC2rFjh6qqquw2BQUF8ng86tu3r93mu+doatPcF7WyvAIAgCFuPxysW7duuuCCC8L2denSRd27d7f3jx07VpMmTVJiYqI8Ho/uvfdeBQIBDR06VJI0fPhw9e3bV7fddptmz56tYDCoadOmKScnx66wjB8/Xs8++6ymTJmiO++8U+vXr9fy5cu1Zs2aZo2X0AEAgCHt8Ymkc+bMUWRkpEaNGqW6ujplZmbqueees49HRUVp9erVuueeexQIBNSlSxeNGTNGM2fOtNukp6drzZo1mjhxoubNm6cePXroxRdfVGZmZrPGwgvfAJwQL3xrPl741v64+cK3YcOGtfiFb5s3b+6wv9+odAAAYEh7rHS0J4QOAAAMIXQ4I3QAAGAIocMZt8wCAABXUOkADOpoF0U2NDS40o8bOvq/INE+UOlwRugAAMAQQoczllcAAIArqHQAAGAIlQ5nhA4AAAwhdDhjeQUAALiCSgcAAIZQ6XBG6AAAwKCOHhxaguUVAADgCiodAAAYwvKKM0IHAACGEDqcEToAADCE0OGMazoAAIArqHQAAGAIlQ5nhA4AAAwhdDhjeQUAALiCSgcAAIZQ6XBG6AAAwBBChzOWVwAAgCuodAAAYAiVDmeEDgAADCF0OGN5BQAAuIJKBwAAhlDpcEboAADAEEKHM0IHAACGEDqccU0HAABwBZUOAAAModLhjNABAIAhhA5nhA6cESzLcqWfI0eOuNJPQ0ODK/24MW+dOnVq9T4k9/4y7+i/NICWIHQAAGAIlQ5nhA4AAAwhdDjj7hUAAOAKKh0AABhCpcMZoQMAAEMIHc5YXgEAAK6g0gEAgEEdvVrREoQOAAAMYXnFGaEDAABDCB3OuKYDAAC4gkoHAACGUOlwRugAAMAQQoczllcAAIArqHQAAGAIlQ5nhA4AAAwhdDhjeQUAALiCSgcAAIZQ6XDWKpWOL7/8Urfeequ6d++u+Ph49evXT++//7593LIszZgxQ8nJyYqPj1dGRob27t3bGkMBAMA1TaGjJVtHZjx0/OMf/9Bll12mTp066e2339bu3bv11FNP6ayzzrLbzJ49W/Pnz9eiRYtUXFysLl26KDMzU7W1taaHAwCAawgdzowvrzzxxBNKTU3V4sWL7X3p6en2f1uWpblz52ratGm64YYbJEmvvPKKfD6fVq1apdGjR5seEgAAaAeMVzrefPNNDR48WD//+c+VlJSkiy66SC+88IJ9vKysTMFgUBkZGfY+r9erIUOGqKio6LjnrKurUygUCtsAAGhvqHQ4Mx46vvjiCy1cuFC9evXSunXrdM899+hXv/qVlixZIkkKBoOSJJ/PF/Y9n89nH/u+vLw8eb1ee0tNTTU9bAAAWozQ4cx46GhsbNTAgQP1+OOP66KLLtK4ceN09913a9GiRad8zqlTp6qmpsbeKioqDI4YAAC4wXjoSE5OVt++fcP29enTR+Xl5ZIkv98vSaqsrAxrU1lZaR/7vtjYWHk8nrANAID2hkqHM+Oh47LLLtOePXvC9n366afq2bOnpG8vKvX7/SosLLSPh0IhFRcXKxAImB4OAACuIXQ4M373ysSJE3XppZfq8ccf17/9279p27Ztev755/X8889L+vZ/kNzcXD366KPq1auX0tPTNX36dKWkpGjkyJGmhwMAANoJ46Hj4osv1sqVKzV16lTNnDlT6enpmjt3rrKzs+02U6ZM0aFDhzRu3DhVV1dr2LBhWrt2reLi4kwPBwAA1/BEUmet8kTS6667Tjt27FBtba0+/vhj3X333WHHIyIiNHPmTAWDQdXW1urdd9/VT37yk9YYCgAArnF7eWXhwoXq37+/fb1jIBDQ22+/bR+vra1VTk6Ounfvrq5du2rUqFHHXFNZXl6urKwsde7cWUlJSZo8ebKOHj0a1mbDhg0aOHCgYmNjdd555yk/P/+U5od3r6DNNTQ0tHof33zzTav3IUkHDhxwpR+3/jXkRvUxOtqdv4Y6+r8gcWbq0aOHZs2apV69esmyLC1ZskQ33HCDPvzwQ51//vmaOHGi1qxZoxUrVsjr9WrChAm66aab9Oc//1nSt3//ZmVlye/3a8uWLfrqq690++23q1OnTnr88cclfft8raysLI0fP15Lly5VYWGh7rrrLiUnJyszM7NZ442wLMsyPgutLBQKyev1qqamhjtZOgBCR/N1pNDRpUuXVu9Dci/cREby8u72xo3fGU19jBs3TjExMad8nvr6ej3//POqqKgIG2tsbKxiY2NP6hyJiYl68skndfPNN+ucc87RsmXLdPPNN0uSPvnkE/Xp00dFRUUaOnSo3n77bV133XXat2+f/fysRYsW6f7779f//d//KSYmRvfff7/WrFmjnTt32n2MHj1a1dXVWrt2bbN+Pv50AABgiKnlldTU1LCHYubl5f1g3w0NDXr11Vd16NAhBQIBlZSU6MiRI2FPAO/du7fS0tLsJ4AXFRWpX79+YQ/szMzMVCgU0q5du+w23z1HU5sTPUXcCcsrAAAYZKISebxKx4ns2LFDgUBAtbW16tq1q1auXKm+ffuqtLRUMTExSkhICGv/3SeAB4PB4z4hvOmYU5tQKKTDhw8rPj7+pH8uQgcAAO1Mcx6E+dOf/lSlpaWqqanR//zP/2jMmDHauHFjK4/w1BA6AAAwpC1umY2JidF5550nSRo0aJC2b9+uefPm6d///d9VX1+v6urqsGrHd58A7vf7tW3btrDzNd3d8t02x3uKuMfjaVaVQ+KaDgAAjGkPTyRtbGxUXV2dBg0apE6dOoU9AXzPnj0qLy+3nwAeCAS0Y8cOVVVV2W0KCgrk8XjsV5oEAoGwczS1OZWniFPpAADgNDV16lSNGDFCaWlpOnDggJYtW6YNGzZo3bp18nq9Gjt2rCZNmqTExER5PB7de++9CgQCGjp0qCRp+PDh6tu3r2677TbNnj1bwWBQ06ZNU05Ojn0dyfjx4/Xss89qypQpuvPOO7V+/XotX75ca9asafZ4CR0AABji9vJKVVWVbr/9dn311Vfyer3q37+/1q1bp3/5l3+RJM2ZM0eRkZEaNWqU6urqlJmZqeeee87+flRUlFavXq177rlHgUBAXbp00ZgxYzRz5ky7TXp6utasWaOJEydq3rx56tGjh1588cVmP6ND4jkdaAd4Tkfz8ZyO5uM5HWcuN5/T8d0Kwamoq6vTggULOuzvN/50AAAAV7C8AgCAIbzwzRmhAwAAQwgdzlheAQAArqDSAQCAIVQ6nBE6AAAwhNDhjNABAIAhhA5nXNMBAABcQaUDAABDqHQ4I3QAAGAIocMZyysAAMAVVDoAADCESoczQgcAAIYQOpyxvAIAAFxBpQMAAEOodDgjdAAAYAihwxnLKwAAwBVUOgAAMIRKhzNCB06osbHRlX6CwWCr97Fv375W70OS6uvrXeknPT3dlX5iYmJavY/oaHf+GoqMpLCL1kfocEboAADAoI4eHFqC6A8AAFxBpQMAAENYXnFG6AAAwBBChzOWVwAAgCuodAAAYAiVDmeEDgAADCF0OGN5BQAAuIJKBwAAhlDpcEboAADAEEKHM5ZXAACAK6h0AABgCJUOZ4QOAAAMIXQ4I3QAAGAIocMZ13QAAABXUOkAAMAQKh3OCB0AABhC6HDG8goAAHAFlQ4AAAyh0uGM0AEAgCGEDmcsrwAAAFdQ6QAAwBAqHc4IHQAAGELocMbyCgAAcAWVDgAADKHS4YzQAQCAIYQOZ4QOAAAM6ujBoSW4pgMAALiCSsdp6OjRo6708/nnn7vSz8qVK1u9j27durV6H5J00UUXudKPx+NxpZ/Y2NhW7yMykn/7oONgecUZoQMAAEMIHc74JwYAAHAFlQ4AAAyh0uGM0AEAgCGEDmcsrwAAAFe0euiYNWuWIiIilJuba++rra1VTk6Ounfvrq5du2rUqFGqrKxs7aEAANCqmiodLdk6slYNHdu3b9fvfvc79e/fP2z/xIkT9dZbb2nFihXauHGj9u3bp5tuuqk1hwIAQKsjdDhrtdBx8OBBZWdn64UXXtBZZ51l76+pqdFLL72kp59+WldddZUGDRqkxYsXa8uWLdq6detxz1VXV6dQKBS2AQCA00urhY6cnBxlZWUpIyMjbH9JSYmOHDkStr93795KS0tTUVHRcc+Vl5cnr9drb6mpqa01bAAAThmVDmetEjpeffVVffDBB8rLyzvmWDAYVExMjBISEsL2+3w+BYPB455v6tSpqqmpsbeKiorWGDYAAC1C6HBm/JbZiooK3XfffSooKFBcXJyRc8bGxrryOGYAAFqCW2adGa90lJSUqKqqSgMHDlR0dLSio6O1ceNGzZ8/X9HR0fL5fKqvr1d1dXXY9yorK+X3+00PBwCADisvL08XX3yxunXrpqSkJI0cOVJ79uwJa3Myd4yWl5crKytLnTt3VlJSkiZPnnzMe742bNiggQMHKjY2Vuedd57y8/ObPV7joePqq6/Wjh07VFpaam+DBw9Wdna2/d+dOnVSYWGh/Z09e/aovLxcgUDA9HAAAHCN28srGzduVE5OjrZu3aqCggIdOXJEw4cP16FDh+w2P3THaENDg7KyslRfX68tW7ZoyZIlys/P14wZM+w2ZWVlysrK0pVXXqnS0lLl5ubqrrvu0rp165o1XuPLK926ddMFF1wQtq9Lly7q3r27vX/s2LGaNGmSEhMT5fF4dO+99yoQCGjo0KGmhwMAgGvcXl5Zu3Zt2Of8/HwlJSWppKREl19+uX3H6LJly3TVVVdJkhYvXqw+ffpo69atGjp0qN555x3t3r1b7777rnw+nwYMGKBHHnlE999/vx566CHFxMRo0aJFSk9P11NPPSVJ6tOnjzZv3qw5c+YoMzPzpMfbJk8knTNnjq677jqNGjVKl19+ufx+v15//fW2GAoAAO3O9x8TUVdXd1Lfq6mpkSQlJiZKOrk7RouKitSvXz/5fD67TWZmpkKhkHbt2mW3+f7dqJmZmSe86/REXHn3yoYNG8I+x8XFacGCBVqwYIEb3QMA4ApTlY7vPxriwQcf1EMPPeT43cbGRuXm5uqyyy6zVxZO5o7RYDAYFjiajjcdc2oTCoV0+PBhxcfHn9TPxwvfAAAwxFToqKiokMfjsfefzB2cOTk52rlzpzZv3nzK/bc2XvgGAEA74/F4wrYfCh0TJkzQ6tWr9d5776lHjx72fr/f/4N3jPr9/mPuZmn6/ENtPB7PSVc5JEIHAADGuH33imVZmjBhglauXKn169crPT097PigQYN+8I7RQCCgHTt2qKqqym5TUFAgj8ejvn372m2+e46mNs2965TlFQAADHH77pWcnBwtW7ZMb7zxhrp162Zfg+H1ehUfHy+v1/uDd4wOHz5cffv21W233abZs2crGAxq2rRpysnJsSss48eP17PPPqspU6bozjvv1Pr167V8+XKtWbOmWeOl0gEAwGlq4cKFqqmp0RVXXKHk5GR7e+211+w2P3THaFRUlFavXq2oqCgFAgHdeuutuv322zVz5ky7TXp6utasWaOCggJdeOGFeuqpp/Tiiy8263ZZiUoHAADGuF3psCzrB9uczB2jPXv21B//+EfH81xxxRX68MMPmzW+7yN0AABgCO9ecUboAADAoI4eHFqCazoAAIArqHQAAGAIyyvOCB0AABhC6HBG6DgNffLJJ670M3fuXFf6+fzzz1u9j/vvv7/V+5C+fZGSG5rzBMCWiIqKcqUfAGcGQgcAAIZQ6XBG6AAAwBBChzPuXgEAAK6g0gEAgCFUOpwROgAAMITQ4YzlFQAA4AoqHQAAGEKlwxmhAwAAQwgdzggdAAAYQuhwxjUdAADAFVQ6AAAwhEqHM0IHAACGEDqcsbwCAABcQaUDAABDqHQ4I3QAAGAIocMZyysAAMAVVDoAADCESoczQgcAAIYQOpyxvAIAAFxBpQMAAEOodDgjdAAAYAihwxmhAwAAQwgdzrimAwAAuIJKBwAABnX0akVLEDoAADCE5RVnLK8AAABXUOkAAMAQKh3OCB0AABhC6HBG6DCsoqKi1fu45JJLWr0PSTp8+LAr/cyaNavV+xg8eHCr9yFJXq/XlX6ioqJc6QcATCJ0AABgCJUOZ4QOAAAMIXQ44+4VAADgCiodAAAYQqXDGaEDAABDCB3OCB0AABhC6HDGNR0AAMAVVDoAADCESoczQgcAAIYQOpyxvAIAAFxBpQMAAEOodDgjdAAAYAihwxnLKwAAwBVUOgAAMIRKhzNCBwAAhhA6nLG8AgAAXEGlAwAAQ6h0OCN0AABgCKHDGaEDAABDCB3OuKYDAAC4gkoHAAAGdfRqRUsQOgAAMITlFWfGl1fy8vJ08cUXq1u3bkpKStLIkSO1Z8+esDa1tbXKyclR9+7d1bVrV40aNUqVlZWmhwIAANoR46Fj48aNysnJ0datW1VQUKAjR45o+PDhOnTokN1m4sSJeuutt7RixQpt3LhR+/bt00033WR6KAAAuKqp0tGSrSMzvryydu3asM/5+flKSkpSSUmJLr/8ctXU1Oill17SsmXLdNVVV0mSFi9erD59+mjr1q0aOnToMeesq6tTXV2d/TkUCpkeNgAALcbyirNWv3ulpqZGkpSYmChJKikp0ZEjR5SRkWG36d27t9LS0lRUVHTcc+Tl5cnr9dpbampqaw8bAIB2b9OmTbr++uuVkpKiiIgIrVq1Kuy4ZVmaMWOGkpOTFR8fr4yMDO3duzeszf79+5WdnS2Px6OEhASNHTtWBw8eDGvzl7/8RT/72c8UFxen1NRUzZ49+5TG26qho7GxUbm5ubrssst0wQUXSJKCwaBiYmKUkJAQ1tbn8ykYDB73PFOnTlVNTY29VVRUtOawAQA4JW4vrxw6dEgXXnihFixYcNzjs2fP1vz587Vo0SIVFxerS5cuyszMVG1trd0mOztbu3btUkFBgVavXq1NmzZp3Lhx9vFQKKThw4erZ8+eKikp0ZNPPqmHHnpIzz//fLPnp1XvXsnJydHOnTu1efPmFp0nNjZWsbGxLTrHN99806Lvn6wnn3yy1fto6VycrJUrV7rSz7Bhw1q9jy5durR6HwDg9vLKiBEjNGLEiOMesyxLc+fO1bRp03TDDTdIkl555RX5fD6tWrVKo0eP1scff6y1a9dq+/btGjx4sCTpmWee0bXXXqvf/va3SklJ0dKlS1VfX6+XX35ZMTExOv/881VaWqqnn346LJycjFardEyYMEGrV6/We++9px49etj7/X6/6uvrVV1dHda+srJSfr+/tYYDAMBpIxQKhW3fva7xZJWVlSkYDIZdzuD1ejVkyBD7coaioiIlJCTYgUOSMjIyFBkZqeLiYrvN5ZdfrpiYGLtNZmam9uzZo3/84x/NGpPx0GFZliZMmKCVK1dq/fr1Sk9PDzs+aNAgderUSYWFhfa+PXv2qLy8XIFAwPRwAABwjanlldTU1LBrGfPy8po9lqZLFnw+X9j+717OEAwGlZSUFHY8OjpaiYmJYW2Od47v9nGyjC+v5OTkaNmyZXrjjTfUrVs3e0Ber1fx8fHyer0aO3asJk2apMTERHk8Ht17770KBALHvXMFAIDThanllYqKCnk8Hnu/W8vqrc146Fi4cKEk6Yorrgjbv3jxYv3iF7+QJM2ZM0eRkZEaNWqU6urqlJmZqeeee870UAAAcJWp0OHxeMJCx6loumShsrJSycnJ9v7KykoNGDDAblNVVRX2vaNHj2r//v329/1+/zEP8Gz63NzLIlpleeV4W1PgkKS4uDgtWLBA+/fv16FDh/T6669zPQcAAAalp6fL7/eHXc4QCoVUXFxsX84QCARUXV2tkpISu8369evV2NioIUOG2G02bdqkI0eO2G0KCgr005/+VGeddVazxsRbZgEAMMTtW2YPHjyo0tJSlZaWSvr24tHS0lKVl5crIiJCubm5evTRR/Xmm29qx44duv3225WSkqKRI0dKkvr06aNrrrlGd999t7Zt26Y///nPmjBhgkaPHq2UlBRJ0n/8x38oJiZGY8eO1a5du/Taa69p3rx5mjRpUrPnhxe+AQBgiNu3zL7//vu68sor7c9NQWDMmDHKz8/XlClTdOjQIY0bN07V1dUaNmyY1q5dq7i4OPs7S5cu1YQJE3T11Vfblz7Mnz/fPu71evXOO+8oJydHgwYN0tlnn60ZM2Y0+3ZZidABAMBp64orrpBlWSc8HhERoZkzZ2rmzJknbJOYmKhly5Y59tO/f3/96U9/OuVxNiF0AABgCO9ecUboAADAEEKHMy4kBQAArqDSAQCAIVQ6nBE6AAAwhNDhjOUVAADgCiodAAAYQqXDGaEDAABDCB3OCB0AABhC6HDGNR0AAMAVVDoAADCoo1crWoLQAQCAISyvOGN5BQAAuIJKBwAAhlDpcEboAADAEEKHM5ZXAACAK6h0AABgCJUOZ4QOAAAMIXQ4Y3kFAAC4gkoHAACGUOlwdsaEjiNHjrjSz/jx41u9j0cffbTV+5Ckbt26udJPR/9DBuDMQehwdsaEDgAAWhuhwxnXdAAAAFdQ6QAAwBAqHc4IHQAAGELocMbyCgAAcAWVDgAADKHS4YzQAQCAIYQOZyyvAAAAV1DpAADAECodzggdAAAYQuhwxvIKAABwBZUOAAAModLhjNABAIAhhA5nhA4AAAwhdDjjmg4AAOAKKh0AABjU0asVLUHoAADAEJZXnLG8AgAAXEGlAwAAQ6h0OCN0AABgCKHDGcsrAADAFVQ6AAAwhEqHM0IHAACGEDqcsbwCAABcQaUDAABDqHQ4I3QAAGAIocMZoQMAAEMIHc7OmNDh9Xo7VD8AAJxuzpjQAQBAa6PS4YzQAQCAIYQOZ9wyCwAAXEGlAwAAQ6h0OCN0AABgCKHDGcsrAADAFVQ6AAAwhEqHM0IHAACGEDqcsbwCAABcQaUDAABDqHQ4I3QAAGAIocNZmy6vLFiwQOeee67i4uI0ZMgQbdu2rS2HAwBAizSFjpZsHVmbhY7XXntNkyZN0oMPPqgPPvhAF154oTIzM1VVVdVWQwIAAK2ozZZXnn76ad1999264447JEmLFi3SmjVr9PLLL+uBBx4Ia1tXV6e6ujr7c01NjSQpFAq5N2AAwGmp6XeFZVmt3teBAwdaVK04cOCAwdG0P20SOurr61VSUqKpU6fa+yIjI5WRkaGioqJj2ufl5enhhx8+Zn9qamqrjhMA0HF8/fXX8nq9rXLumJgY+f1+I7+X/H6/YmJiDIyq/WmT0PH3v/9dDQ0N8vl8Yft9Pp8++eSTY9pPnTpVkyZNsj9XV1erZ8+eKi8vb7X/A3VUoVBIqampqqiokMfjaevhnHaYv1PH3LUM83fqampqlJaWpsTExFbrIy4uTmVlZaqvr2/xuWJiYhQXF2dgVO3PaXH3SmxsrGJjY4/Z7/V6+cN3ijweD3PXAszfqWPuWob5O3WRka17GWNcXFyHDQumtMmFpGeffbaioqJUWVkZtr+yslJ+v78thgQAAFpZm4SOmJgYDRo0SIWFhfa+xsZGFRYWKhAItMWQAABAK2uz5ZVJkyZpzJgxGjx4sC655BLNnTtXhw4dsu9mcRIbG6sHH3zwuEsucMbctQzzd+qYu5Zh/k4dc9d+RFhu3EN0As8++6yefPJJBYNBDRgwQPPnz9eQIUPaajgAAKAVtWnoAAAAZw7eMgsAAFxB6AAAAK4gdAAAAFcQOgAAgCtOy9CxYMECnXvuuYqLi9OQIUO0bdu2th5Su5OXl6eLL75Y3bp1U1JSkkaOHKk9e/aEtamtrVVOTo66d++url27atSoUcc8sA3SrFmzFBERodzcXHsfc3diX375pW699VZ1795d8fHx6tevn95//337uGVZmjFjhpKTkxUfH6+MjAzt3bu3DUfcfjQ0NGj69OlKT09XfHy8fvzjH+uRRx4Je1EZ8/etTZs26frrr1dKSooiIiK0atWqsOMnM0/79+9Xdna2PB6PEhISNHbsWB08eNDFn+IMZJ1mXn31VSsmJsZ6+eWXrV27dll33323lZCQYFVWVrb10NqVzMxMa/HixdbOnTut0tJS69prr7XS0tKsgwcP2m3Gjx9vpaamWoWFhdb7779vDR061Lr00kvbcNTtz7Zt26xzzz3X6t+/v3XffffZ+5m749u/f7/Vs2dP6xe/+IVVXFxsffHFF9a6deuszz77zG4za9Ysy+v1WqtWrbI++ugj61//9V+t9PR06/Dhw2048vbhscces7p3726tXr3aKisrs1asWGF17drVmjdvnt2G+fvWH//4R+s3v/mN9frrr1uSrJUrV4YdP5l5uuaaa6wLL7zQ2rp1q/WnP/3JOu+886xbbrnF5Z/kzHLahY5LLrnEysnJsT83NDRYKSkpVl5eXhuOqv2rqqqyJFkbN260LMuyqqurrU6dOlkrVqyw23z88ceWJKuoqKithtmuHDhwwOrVq5dVUFBg/fM//7MdOpi7E7v//vutYcOGnfB4Y2Oj5ff7rSeffNLeV11dbcXGxlp/+MMf3Bhiu5aVlWXdeeedYftuuukmKzs727Is5u9Evh86Tmaedu/ebUmytm/fbrd5++23rYiICOvLL790bexnmtNqeaW+vl4lJSXKyMiw90VGRiojI0NFRUVtOLL2r6amRpLstyyWlJToyJEjYXPZu3dvpaWlMZf/X05OjrKyssLmSGLunLz55psaPHiwfv7znyspKUkXXXSRXnjhBft4WVmZgsFg2Nx5vV4NGTLkjJ87Sbr00ktVWFioTz/9VJL00UcfafPmzRoxYoQk5u9kncw8FRUVKSEhQYMHD7bbZGRkKDIyUsXFxa6P+UxxWrxltsnf//53NTQ0yOfzhe33+Xz65JNP2mhU7V9jY6Nyc3N12WWX6YILLpAkBYNBxcTEKCEhIaytz+dTMBhsg1G2L6+++qo++OADbd++/ZhjzN2JffHFF1q4cKEmTZqk//7v/9b27dv1q1/9SjExMRozZow9P8f7M3ymz50kPfDAAwqFQurdu7eioqLU0NCgxx57TNnZ2ZLE/J2kk5mnYDCopKSksOPR0dFKTExkLlvRaRU6cGpycnK0c+dObd68ua2HclqoqKjQfffdp4KCAl5T3UyNjY0aPHiwHn/8cUnSRRddpJ07d2rRokUaM2ZMG4+u/Vu+fLmWLl2qZcuW6fzzz1dpaalyc3OVkpLC/KFDOK2WV84++2xFRUUdc5dAZWWl/H5/G42qfZswYYJWr16t9957Tz169LD3+/1+1dfXq7q6Oqw9c/nt8klVVZUGDhyo6OhoRUdHa+PGjZo/f76io6Pl8/mYuxNITk5W3759w/b16dNH5eXlkmTPD3+Gj2/y5Ml64IEHNHr0aPXr10+33XabJk6cqLy8PEnM38k6mXny+/2qqqoKO3706FHt37+fuWxFp1XoiImJ0aBBg1RYWGjva2xsVGFhoQKBQBuOrP2xLEsTJkzQypUrtX79eqWnp4cdHzRokDp16hQ2l3v27FF5efkZP5dXX321duzYodLSUnsbPHiwsrOz7f9m7o7vsssuO+bW7E8//VQ9e/aUJKWnp8vv94fNXSgUUnFx8Rk/d5L0zTffKDIy/K/lqKgoNTY2SmL+TtbJzFMgEFB1dbVKSkrsNuvXr1djYyMvHm1NbX0la3O9+uqrVmxsrJWfn2/t3r3bGjdunJWQkGAFg8G2Hlq7cs8991her9fasGGD9dVXX9nbN998Y7cZP368lZaWZq1fv956//33rUAgYAUCgTYcdfv13btXLIu5O5Ft27ZZ0dHR1mOPPWbt3bvXWrp0qdW5c2fr97//vd1m1qxZVkJCgvXGG29Yf/nLX6wbbrjhjLzl83jGjBlj/dM//ZN9y+zrr79unX322daUKVPsNszftw4cOGB9+OGH1ocffmhJsp5++mnrww8/tP76179alnVy83TNNddYF110kVVcXGxt3rzZ6tWrF7fMtrLTLnRYlmU988wzVlpamhUTE2Ndcskl1tatW9t6SO2OpONuixcvttscPnzY+uUvf2mdddZZVufOna0bb7zR+uqrr9pu0O3Y90MHc3dib731lnXBBRdYsbGxVu/eva3nn38+7HhjY6M1ffp0y+fzWbGxsdbVV19t7dmzp41G276EQiHrvvvus9LS0qy4uDjrRz/6kfWb3/zGqqurs9swf9967733jvt33JgxYyzLOrl5+vrrr61bbrnF6tq1q+XxeKw77rjDOnDgQBv8NGcOXm0PAABccVpd0wEAAE5fhA4AAOAKQgcAAHAFoQMAALiC0AEAAFxB6AAAAK4gdAAAAFcQOgAAgCsIHQAAwBWEDgAA4ApCBwAAcMX/A/eAFlOWdYTNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(en_lengths, pl_lengths, bins=40, cmap='binary', cmin=4)\n",
    "plt.xlim((0, 100))\n",
    "plt.ylim((0, 100))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_EMBEDDING_DIM = 256\n",
    "DECODER_EMBEDDING_DIM = 256\n",
    "ENCODER_HIDDEN_DIM = 256\n",
    "DECODER_HIDDEN_DIM = 256\n",
    "SAVE_DIR = os.path.join(\".\", \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, hidden = self.encoder(x)\n",
    "\n",
    "\n",
    "class BahdanauEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim,\n",
    "                 encoder_hidden_dim, decoder_hidden_dim, dropout_p):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, encoder_hidden_dim,\n",
    "                          bidirectional=True)\n",
    "        # Times 2 because of bidirectional (I guess)\n",
    "        self.linear = nn.Linear(encoder_hidden_dim*2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        hidden = torch.tanh(self.linear(\n",
    "            torch.cat((hidden[-2, :, :], hidden[-1, :, :]),\n",
    "                      dim=1)\n",
    "        ))\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, query_size=None,\n",
    "                 key_size=None, dropout_p=0.15):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.query_size = hidden_size if query_size is None else query_size\n",
    "        # Assume that encoder is bidirectional (times 2)\n",
    "        self.key_size = 2*hidden_size if key_size is None else key_size\n",
    "\n",
    "        self.query_layer = nn.Linear(self.query_size, hidden_size)\n",
    "        self.key_layer = nn.Linear(self.key_size, hidden_size)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, src_mask=None):\n",
    "        query_out = self.query_layer(hidden)\n",
    "        key_out = self.key_layer(encoder_outputs)\n",
    "        energy_input = torch.tanh(query_out + key_out)\n",
    "        energies = self.energy_layer(energy_input).squeeze(2)\n",
    "\n",
    "        if src_mask is not None:\n",
    "            energies.data.masked_fill_(src_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        weights = torch.softmax(energies, dim=0)\n",
    "        return weights.transpose(0, 1)\n",
    "\n",
    "\n",
    "class BahdanauDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, encoder_hidden_dim,\n",
    "                 decoder_hidden_dim, attention, dropout_p):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.attention = attention\n",
    "        self.gru = nn.GRU((encoder_hidden_dim*2) +\n",
    "                          embedding_dim, decoder_hidden_dim)\n",
    "        self.out = nn.Linear((encoder_hidden_dim*2) +\n",
    "                             embedding_dim+decoder_hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, src_mask=None):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        attentions = self.attention(hidden, encoder_outputs, src_mask)\n",
    "        a = attentions.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)\n",
    "\n",
    "        '''Multiplying two matrices that are batched. If 1st batched matrix size is (10, 3, 5) \n",
    "        and 2nd batched matrix size is (10, 5, 6) then output matrix size will be (10, 3, 6)'''\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        weighted = weighted.transpose(0, 1)\n",
    "\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
    "\n",
    "        assert (output == hidden).all()\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "\n",
    "        linear_input = torch.cat((output, weighted, embedded), dim=1)\n",
    "\n",
    "        output = self.out(linear_input)\n",
    "        return output, hidden.squeeze(0), attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'en_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m     seq2seq \u001b[38;5;241m=\u001b[39m BahdanauSeq2Seq(enc, dec, device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m enc \u001b[38;5;241m=\u001b[39m BahdanauEncoder(\u001b[38;5;28mlen\u001b[39m(\u001b[43men_vocab\u001b[49m), ENCODER_EMBEDDING_DIM,\n\u001b[1;32m      8\u001b[0m                       ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, \u001b[38;5;241m0.15\u001b[39m)\n\u001b[1;32m      9\u001b[0m attn \u001b[38;5;241m=\u001b[39m BahdanauAttention(DECODER_HIDDEN_DIM)\n\u001b[1;32m     10\u001b[0m dec \u001b[38;5;241m=\u001b[39m BahdanauDecoder(\u001b[38;5;28mlen\u001b[39m(fr_vocab), DECODER_EMBEDDING_DIM,\n\u001b[1;32m     11\u001b[0m                       ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, attn, \u001b[38;5;241m0.15\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'en_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    enc = BahdanauEncoder(len(en_vocab), ENCODER_EMBEDDING_DIM,\n",
    "                          ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, 0.15)\n",
    "    attn = BahdanauAttention(DECODER_HIDDEN_DIM)\n",
    "    dec = BahdanauDecoder(len(fr_vocab), DECODER_EMBEDDING_DIM,\n",
    "                          ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, attn, 0.15)\n",
    "    seq2seq = BahdanauSeq2Seq(enc, dec, device)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
